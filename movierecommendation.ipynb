{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd \n",
    "import string \n",
    "import random \n",
    "import csv\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.classify import NaiveBayesClassifier, accuracy\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENGLISH_STOPWORDS = stopwords.words('English')\n",
    "PUNCTUATIONS = string.punctuation\n",
    "LEMMATIZER = WordNetLemmatizer()\n",
    "STEMMER = PorterStemmer()\n",
    "FILE_PATH =\"./filtered_data.csv\"\n",
    "SEED_VALUE = 1234\n",
    "NLP_ENG_MODEL = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "review_text = \"\"\n",
    "classifier = 0\n",
    "list_words = []\n",
    "labeled = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = pd.read_csv(FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init():\n",
    "    \n",
    "    global list_words\n",
    "    global labeled\n",
    "    \n",
    "    random.seed(SEED_VALUE)\n",
    "    \n",
    "    data = []\n",
    "    with open(FILE_PATH, encoding='UTF-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            data.append(row)\n",
    "    \n",
    "    random.shuffle(data)\n",
    "    \n",
    "    for d in data:\n",
    "        sentence = d[1].lower()\n",
    "        sentence = ''.join([i for i in sentence if not i.isdigit()])\n",
    "        sentence = re.sub(r'\\W+\\d+', '', sentence)\n",
    "        words = word_tokenize(sentence)\n",
    "        words = [word for word in words if word not in ENGLISH_STOPWORDS]\n",
    "        words = [STEMMER.stem(word) for word in words]\n",
    "        words = [LEMMATIZER.lemmatize(word) for word in words]\n",
    "        words = [word for word in words if word not in string.punctuation]\n",
    "        words = [word for word in words if word.isalpha()]\n",
    "        \n",
    "        for w in words:\n",
    "            list_words.append(w)\n",
    "        labeled.append((d[0], d[1], d[2]))\n",
    "    \n",
    "    fd = FreqDist(list_words)\n",
    "    list_words = [word for word, count, in fd.most_common(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    global dataset\n",
    "    global labeled\n",
    "    global classifier\n",
    "    \n",
    "    for title, sentence, label in labeled:\n",
    "        words = word_tokenize(sentence)\n",
    "        words = [word for word in words if word not in ENGLISH_STOPWORDS]\n",
    "        words = [STEMMER.stem(word) for word in words]\n",
    "        words = [LEMMATIZER.lemmatize(word) for word in words]\n",
    "        words = [word for word in words if word not in PUNCTUATIONS]\n",
    "        words = [word for word in words if word.isalpha()]\n",
    "        \n",
    "        try:\n",
    "            # if label == 'NEGATIVE':\n",
    "            #     newlabel = \"negative\"\n",
    "            # elif label == 'POSITIVE':\n",
    "            #     newlabel = 'positive'\n",
    "            # else:\n",
    "            #     print(f\"[!] WARNING: UNEXPECTED LABEL VALUE '{label}\")\n",
    "            #     continue\n",
    "            dict = {}\n",
    "            for feature in list_words:\n",
    "                key = feature\n",
    "                value = feature in words\n",
    "                dict[key] = value\n",
    "            dataset.append((dict, label))\n",
    "        except ValueError:\n",
    "            print(f\"[!] WARNING: COULD NOT CONVERT LABEL '{label}' TO AN CATEGORICAL VALUES\")\n",
    "    \n",
    "    percentage = int(len(dataset) * 0.85)\n",
    "    \n",
    "    training_data = dataset[:percentage]\n",
    "    testing_data = dataset[percentage:]\n",
    "    \n",
    "    classifier = NaiveBayesClassifier.train(training_data)\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"MODEL TRANING ACCURACY: \" + str(accuracy(classifier, testing_data)*100)+\"%\")\n",
    "    file = open('model.pickle', 'wb')\n",
    "    pickle.dump(classifier, file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeReview():\n",
    "    os.system('cls')\n",
    "    global review_text\n",
    "    \n",
    "    while(True):\n",
    "        review = input(\"[#] INPUT YOUR REVIEW [MORE THAN 20 WORDS]: \")\n",
    "        cleaned = [word for word in word_tokenize(review) if word not in string.punctuation]\n",
    "        if len(cleaned) < 20:\n",
    "            print(\"[!] YOUR REVIEW MUST CONSIST OF AT LEAST 20 WORDS!\")\n",
    "        else:\n",
    "            input(\"[!] PRESS ENTER TO CONTINUE\")\n",
    "            break\n",
    "    review_text = review\n",
    "    menu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyzeReview():\n",
    "    if(review_text == ''):\n",
    "        print(\"[!] YOU NEED TO WRITE REVIEW\")\n",
    "        input(\"[!] PRESS ENTER TO CONTINUE\")\n",
    "        menu()\n",
    "    else:\n",
    "        review = review_text.lower()\n",
    "        words = word_tokenize(review)\n",
    "        words = [word for word in words if word not in ENGLISH_STOPWORDS]\n",
    "        words = [word for word in words if word not in string.punctuation]\n",
    "        words = [LEMMATIZER.lemmatize(word) for word in words]\n",
    "        words = [word for word in words if word.isalpha()]\n",
    "        \n",
    "        classification = classifier.classify(FreqDist(words))\n",
    "        \n",
    "        return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viewRecommendedMovie():\n",
    "    os.system('cls')\n",
    "    \n",
    "    print(list_words)\n",
    "    global review_text\n",
    "    \n",
    "    if(review_text == ''):\n",
    "        print(\"  [!] YOU NEED TO WRITE A REVIEW FIRST!\")\n",
    "        input(\"  [>] PRESS ENTER TO CONTINUE...\")\n",
    "        menu()\n",
    "    else:\n",
    "        # Word Embedding (TF-IDF)\n",
    "        tfidf_vectorizer = TfidfVectorizer(vocabulary=list_words)\n",
    "        movie_tfidf_matrix = tfidf_vectorizer.fit_transform([review[1] for review in labeled])\n",
    "        user_tfidf_vector = tfidf_vectorizer.transform([review_text])\n",
    "\n",
    "        # Count cosine similarity\n",
    "        cosine_similarities = cosine_similarity(user_tfidf_vector, movie_tfidf_matrix)\n",
    "        \n",
    "        top_indices = cosine_similarities.argsort(axis=1)[0][-2:][::-1]\n",
    "        top_movies = [(labeled[i][0]) for i in top_indices] \n",
    "        \n",
    "        # Return the result\n",
    "        print('  TOP 2 MOVIE RECOMMENDATION FOR YOU:')\n",
    "        for i in range(2):\n",
    "            print(f'  {i+1}: {top_movies[i]}')\n",
    "        \n",
    "        print()  \n",
    "        input(\"  [>] PRESS ENTER TO CONTINUE...\")\n",
    "        menu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viewNamedEntityRecognition():\n",
    "    doc = NLP_ENG_MODEL(review_text)\n",
    "    entities = {}\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        entities.setdefault(ent.label_, []).append(ent.text)\n",
    "    for category, names in entities.items():\n",
    "        print(f\"{category}: {','.join(names)}\")\n",
    "    menu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def menu():\n",
    "    os.system('cls')\n",
    "    print('MOVIE RECMMENDATION APPLICTION BASED ON REVIEWS')\n",
    "    print('YOUR REVIEW: ', \"NO REVIEW\" if not review_text else review_text)\n",
    "    print(\"YOUR REVIEW: \", \"UNKNOWN\" if not review_text else analyzeReview())\n",
    "    print(\"1. WRITE YOUR REVIEW\")\n",
    "    print(\"2. VIEW MOVIE RECOMMENDATION\")\n",
    "    print(\"3. VIEW NAMED ENTITIES RECOGNITION\")\n",
    "    print(\"4. EXIT\")\n",
    "    \n",
    "    while(True):\n",
    "        try:\n",
    "            opt = int(input(\">>\"))\n",
    "            if opt < 1 or opt > 4:\n",
    "                print(\"[!] PLEASE ENTER A NUMBER BETWEEN 1 AND 4 (INCLUSIVE)\")\n",
    "            else:\n",
    "                break\n",
    "        except ValueError:\n",
    "            print(\"[!] INVALID INPUT. PLEASE ENTER A NUMBER!\")\n",
    "    \n",
    "    if int(opt) == 1:\n",
    "        writeReview()\n",
    "    elif int(opt) == 2:\n",
    "        viewRecommendedMovie()\n",
    "    elif int(opt) == 3:\n",
    "        viewNamedEntityRecognition()\n",
    "    elif int(opt) == 4:\n",
    "        os.system(\"cls\")\n",
    "        print(\"[>] THANK YOU FOOR USING THIS APPLICATION\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    init()\n",
    "    os.system('cls')\n",
    "    \n",
    "    global classifier\n",
    "    \n",
    "    if os.path.isfile(\"model.pickle\"):\n",
    "        file = open(\"model.pickle\", 'rb')\n",
    "        classifier = pickle.load(file)\n",
    "        file.close()\n",
    "        \n",
    "        print(\"[>] LOAD MODEL COMPLETE...\")\n",
    "    else:\n",
    "        print(\"[>] TRAINING...\")\n",
    "        train_model()\n",
    "        print(\"[>] TRAINING MODEL COMPLETE...\")\n",
    "    input(\"[>] PRESS ENTER TO CONTINUE...\")\n",
    "    menu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>] LOAD MODEL COMPLETE...\n",
      "MOVIE RECMMENDATION APPLICTION BASED ON REVIEWS\n",
      "YOUR REVIEW:  It's a film from which you'd expect the moon, the stars and the sun. What with an actor like Crowe and a director like Scott. Disappointingly, the talented duo gives you the most wishy-washy film of the year.\n",
      "YOUR REVIEW:  positive\n",
      "1. WRITE YOUR REVIEW\n",
      "2. VIEW MOVIE RECOMMENDATION\n",
      "3. VIEW NAMED ENTITIES RECOGNITION\n",
      "4. EXIT\n",
      "[!] INVALID INPUT. PLEASE ENTER A NUMBER!\n",
      "['film', 'movi', 'one', 'like', 'make', 'charact', 'stori', 'perform', 'time', 'comedi', 'good', 'much', 'full', 'even', 'feel', 'best', 'get', 'love', 'work', 'action', 'entertain', 'review', 'way', 'great', 'enough', 'end', 'spanish', 'fun', 'take', 'audienc', 'director', 'come', 'never', 'watch', 'littl', 'well', 'drama', 'could', 'see', 'funni', 'moment', 'plot', 'may', 'cast', 'go', 'would', 'still', 'enjoy', 'seem', 'look', 'emot', 'effect', 'mani', 'laugh', 'better', 'thing', 'year', 'realli', 'thriller', 'made', 'yet', 'act', 'also', 'everi', 'life', 'give', 'new', 'first', 'quit', 'visual', 'someth', 'two', 'script', 'play', 'horror', 'u', 'humor', 'want', 'scene', 'interest', 'lot', 'despit', 'origin', 'world', 'bad', 'bit', 'far', 'keep', 'though', 'turn', 'without', 'filmmak', 'find', 'noth', 'genr', 'gener', 'part', 'kind', 'might', 'romant']\n",
      "  TOP 2 MOVIE RECOMMENDATION FOR YOU:\n",
      "  1: A Good Year\n",
      "  2: A Good Year\n",
      "\n",
      "MOVIE RECMMENDATION APPLICTION BASED ON REVIEWS\n",
      "YOUR REVIEW:  It's a film from which you'd expect the moon, the stars and the sun. What with an actor like Crowe and a director like Scott. Disappointingly, the talented duo gives you the most wishy-washy film of the year.\n",
      "YOUR REVIEW:  positive\n",
      "1. WRITE YOUR REVIEW\n",
      "2. VIEW MOVIE RECOMMENDATION\n",
      "3. VIEW NAMED ENTITIES RECOGNITION\n",
      "4. EXIT\n",
      "[>] THANK YOU FOOR USING THIS APPLICATION\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
